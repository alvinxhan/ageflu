{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age-association analyses of closely-related HA sequence pairs\n",
    "\n",
    "## Overview \n",
    "In this notebook, we demonstrate the analyses performed in our manuscript entitiled, \"Individual immune selection pressure has limited impact on seasonal influenza virus evolution\". As an example, we show how we analysed for the hemagglutinin (HA) sequences of A/H3N2 collected between 2009 and July-2016.\n",
    "\n",
    "## Pre-analysis tasks \n",
    "### Sequence curation\n",
    "We collected all sequences from [GISAID](http://www.gisaid.org/) and [NCBI Genbank](http://www.ncbi.nlm.nih.gov/genbank/) databases that satisfy the following filters: \n",
    "  1. \\>90% of full HA nucleotide length \n",
    "  2. availability of patients' age data \n",
    "  3. availability of virus passage history that could be categorized as original clinical material, MDCK, SIAT and egg passage types (Typing of passage histories was based on [Chan et al., 2016](https://www.ncbi.nlm.nih.gov/pubmed/27604224)). \n",
    "\n",
    "In total, 10,514 HA nucleotide sequences were obtained for A/H3N2.\n",
    "\n",
    "We further processed the sequences obtained by: \n",
    "  1. Removed duplicated and low quality (\\>10% residues missing or ambiguous) were removed. \n",
    "  2. Sequences of the same virus but different passage histories were prioritized by clinical > MDCK > SIAT > egg and/or lower passage number. **At this point, there are 8,530 sequences for A/H3N2** (i.e. H3N2-HA-nuc.fa in [Files](https://github.com/alvinxhan/ageflu/tree/master/files) folder). \n",
    "  3. Clustered and removed identical nucleotide sequences using CD-HIT, leaving behind a representative strain for each cluster to yield a final set of non-redundant sequences. You can find the CD-HIT sequence cluster output file (e.g. H3N2-HA-nuc_cd-hit-non-redundant.clstr) in the [Files](https://github.com/alvinxhan/ageflu/tree/master/files) folder. \n",
    "  \n",
    "In total, there were 6,033 non-redudant sequences for A/H3N2. \n",
    "\n",
    "### Maximum-likelihood tree reconstruction\n",
    "Prior to the analyses presented here, we first reconstruct a maximum-likelihood (ML) phylogenetic tree using HA nucleotide sequences. Due to the large number of sequences (n=6,033 for A/H3N2) and the relatively low observed genetic divergence (overall mean nucleotide p-distance of A/H3N2 calculated by MEGA = 0.00964), conventional phylogenetic methods would be computationally expensive and practically infeasible. As such, we reconstructed our ML trees with RAxML and GARLI, using a nested inference approach that we have developed. More information on this phylogenetic inference methodology can be found in our paper. \n",
    "\n",
    "The phylogenetic tree for A/H3N2 (H3N2-HA-nuc.rooted.nwk) can be found in the [Files](https://github.com/alvinxhan/ageflu/tree/master/files) folder as well. \n",
    "\n",
    "## Getting evolutionarily closest pairs\n",
    "We now can parse for evolutionarily closely-related virus pairs from the inferred phylogenetic tree. You can do so using [ageflu_getpairs.py](https://github.com/alvinxhan/ageflu/blob/master/scripts/ageflu_getpairs.py). \n",
    "\n",
    "* Additional inputs include: (i) FASTA alignment of all sequences (including identical nucleotide sequences), (ii) CD-HIT cluster file of non-redundant sequence clusters.\n",
    "* The age limits of children and adults can be changed using the '--child' and '--adult' arguments.\n",
    "* Note that the FASTA alignment containing reference sequences for HA-numbering ('H1pdm09_H3_FluB_NumberingRef.fa') must be in the same folder as the ageflu_getpairs.py script.\n",
    "* Tab-delimited output: ageflu_evol-closest-pairs.*.txt\n",
    "\n",
    "Here, we show the breakdown of the script:\n",
    "\n",
    "### Importing modules and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "from decimal import *\n",
    "import re, sys, itertools\n",
    "import ete3\n",
    "import random\n",
    "\n",
    "random.seed(666)\n",
    "\n",
    "# parse fasta file\n",
    "def parsefasta(file, check_alg=1, check_dna=1, check_codon=1):\n",
    "    # check if file is of FASTA format\n",
    "    fhandle = filter(None, open(file, 'rU').readlines())\n",
    "    if not re.search('^>', fhandle[0]): sys.exit('\\nERROR: Incorrect sequence file format.\\n')\n",
    "\n",
    "    result = {}\n",
    "    for key, group in itertools.groupby(fhandle, lambda _: re.search('^>',_)):\n",
    "        if key:\n",
    "            header = group.next().strip().replace('>','')\n",
    "        else:\n",
    "            sequence = ''.join(map(lambda _:_.strip(),list(group)))\n",
    "            # dna sequences\n",
    "            if check_dna == 1 and set(list(sequence))&set(list('rhkdesqpvilmfyw')):\n",
    "                sys.exit('\\nERROR: Input must be DNA FASTA.\\n')\n",
    "            # codon-alignment\n",
    "            if check_codon == 1 and len(sequence)%3 > 0:\n",
    "                sys.exit('\\nERROR: DNA sequence file given must be codon-aligned.\\n')\n",
    "            result[header] = sequence\n",
    "    # alignment\n",
    "    if check_alg == 1 and len(set(map(len, result.values()))) != 1:\n",
    "        sys.exit('\\nERROR: Input sequence file must be an alignment.\\n')\n",
    "    return result\n",
    "\n",
    "# translate codon-aligned nucleotide sequences\n",
    "def translatedDNA(dna):\n",
    "    protein = []\n",
    "    for _ in xrange(0,len(dna),3):\n",
    "        codon = dna[_:_+3]\n",
    "        if codon in dnacodontable:\n",
    "            if dnacodontable[codon] == 'stop': break\n",
    "            protein.append(dnacodontable[codon])\n",
    "        elif re.match('---',codon): protein.append('-')\n",
    "        else: protein.append('X')\n",
    "    return ''.join(protein)\n",
    "\n",
    "# get pairwise substitutions\n",
    "def get_pairwise_substitutions(anc_seq, desc_seq):\n",
    "    # nucleotide sequences input\n",
    "    if set(list(anc_seq)) <= set(list('atgcn-')):\n",
    "        transitions, transversions, nonsyn_sub, syn_sub = 0, 0, 0, 0\n",
    "        for _ in xrange(0, len(anc_seq), 3):\n",
    "            anc_codon = anc_seq[_:_+3]\n",
    "            desc_codon = desc_seq[_:_+3]\n",
    "            if anc_codon == desc_codon:\n",
    "                continue\n",
    "            else:\n",
    "                unknown_res_binary = 0\n",
    "                nuc_sub = 0\n",
    "                for j in xrange(3):\n",
    "                    if re.match('(n|-)', anc_codon[j]) or re.match('(n|-)', desc_codon[j]):\n",
    "                        unknown_res_binary = 1\n",
    "                        continue\n",
    "                    elif anc_codon[j] != desc_codon[j]:\n",
    "                        if re.search('(ag|ga|ct|tc)', ''.join([anc_codon[j], desc_codon[j]])):\n",
    "                            transitions += 1\n",
    "                            nuc_sub += 1\n",
    "                        else:\n",
    "                            transversions += 1\n",
    "                            nuc_sub += 1\n",
    "\n",
    "                if unknown_res_binary == 1:\n",
    "                    continue\n",
    "                if dnacodontable[anc_codon] != dnacodontable[desc_codon]:\n",
    "                    nonsyn_sub += nuc_sub\n",
    "                else:\n",
    "                    syn_sub += nuc_sub\n",
    "        return {'transitions':transitions, 'transversions':transversions, 'nonsyn':nonsyn_sub, 'syn':syn_sub}\n",
    "    # protein sequences input\n",
    "    else:\n",
    "        mutation_list = []\n",
    "        for _ in xrange(len(anc_seq)):\n",
    "            if re.search('(-|X)', anc_seq[_]) or re.search('(-|X)', desc_seq[_]):\n",
    "                continue\n",
    "            elif anc_seq[_] != desc_seq[_]:\n",
    "                mutation_list.append('{}{}{}'.format(anc_seq[_], _+1, desc_seq[_]))\n",
    "        return mutation_list\n",
    "\n",
    "def get_least_unknown_residue_sequences(seq_dict, dist_dict_to_edit={}):\n",
    "    seqid_to_unknownrescount = {seqid:len(re.findall('(-|n|X)', sequence, re.I)) for seqid, sequence in seq_dict.items()}\n",
    "    seqid_with_least_unknown_res = [seqid for seqid, count in seqid_to_unknownrescount.items() if count == min(seqid_to_unknownrescount.values())]\n",
    "    if len(dist_dict_to_edit) > 0:\n",
    "        for seqid in list(set(seq_dict.keys())-set(seqid_with_least_unknown_res)):\n",
    "            del dist_dict_to_edit[seqid]\n",
    "        return seqid_with_least_unknown_res, dist_dict_to_edit\n",
    "    else:\n",
    "        return seqid_with_least_unknown_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inputs \n",
    "\n",
    "You can choose to analyse other influenza subtypes/lineages by changing ```subtype_to_analyse``` here. You can also opt to analyse only closely-related viruses of the same passage cell type by changing ```passage_requirement = 'T'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_to_analyse = 'H3N2'\n",
    "passage_requirement = 'F'\n",
    "\n",
    "subtype_to_passage_to_age_range = {'T':{'H3N2':{'child':[0, 12], 'adult':[25, 120]},\n",
    "                                        'H1N1pdm09':{'child':[0, 5], 'adult':[20, 120]},\n",
    "                                        'BVic':{'child':[0, 10], 'adult':[35, 120]},\n",
    "                                        'BYam':{'child':[0, 10], 'adult':[35, 120]}},\n",
    "                                   'F':{'H3N2':{'child':[0, 5], 'adult':[35, 120]},\n",
    "                                        'H1N1pdm09':{'child':[0, 5], 'adult':[25, 120]},\n",
    "                                        'BVic':{'child':[0, 10], 'adult':[20, 120]},\n",
    "                                        'BYam':{'child':[0, 5], 'adult':[35, 120]}}}\n",
    "\n",
    "class params:\n",
    "    tree = './files/{st}/{st}-HA-nuc_rooted.nwk'.format(st=subtype_to_analyse) # Phylogenetic tree file in NEWICK format \n",
    "    aln = './files/{st}/{st}-HA-nuc.fa'.format(st=subtype_to_analyse) # Nucleotide alignment of HA sequences (pre-CD-HIT)\n",
    "    nr = './files/{st}/{st}-HA-nuc_cd-hit-non-redundant.clstr'.format(st=subtype_to_analyse) # CD-HIT identical sequence cluster file \n",
    "    child = subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['child'] # age range of children \n",
    "    adult = subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['adult'] # age range of adults \n",
    "    maxmut = 5 # maxmimum number of amino acid substitutions allowable in an evolutionarily closest pair \n",
    "    patdist = 0.007 # maximum patristic distance between sequences in a closest pair\n",
    "    order = 3 # max ordinal of pairs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse FASTA and CD-HIT files \n",
    "We sort CD-HIT identical sequence clusters into age categories ([C]hild, [A]dult or [U]ncateogrized) based on input children and adults age ranges. \n",
    "\n",
    "Any sequences in the an [U]ncategorized cluster will **NOT** be used for pairing in the subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE of the age category of a CD-HIT cluster:\n",
      "Representative sequence = A/SouthCarolina/22/2016_HA_EPIISL225062_2016.39767283_ORI/CLI_A/H3N2_LAT33.836081LON-81.163724_AGE18\n",
      "Age category: U\n",
      "Member sequences:\n",
      "A/SouthCarolina/19/2016_HA_EPIISL225061_2016.39493498_ORI/CLI_A/H3N2_LAT33.836081LON-81.163724_AGE19\n",
      "A/SouthCarolina/25/2016_HA_EPIISL225067_2016.39767283_ORI/CLI_A/H3N2_LAT33.836081LON-81.163724_AGE19\n",
      "A/SouthCarolina/17/2016_HA_EPIISL225128_2016.39219713_ORI/CLI_A/H3N2_LAT33.836081LON-81.163724_AGE25\n",
      "A/SouthCarolina/22/2016_HA_EPIISL225062_2016.39767283_ORI/CLI_A/H3N2_LAT33.836081LON-81.163724_AGE18\n"
     ]
    }
   ],
   "source": [
    "# query subtype analysed \n",
    "try:\n",
    "    query_subtype = re.search('(H3N2|pH1N1|H1N1pdm09|BVic|BYam)', params.tree).group().upper()\n",
    "    if query_subtype == 'PH1N1':\n",
    "        query_subtype = 'H1N1PDM09'\n",
    "except:\n",
    "    query_subtype = raw_input('\\nWARNING: Can\\'t parsed query subtype from tree name. Enter subtype (H3N2/pH1N1/BVic/BYam): ')\n",
    "\n",
    "# output filename\n",
    "outfname = '{}C{}_{}A{}_PD{}_MM{}_CL{}_{}'.format(params.child[0], params.child[-1], params.adult[0], params.adult[-1], params.patdist, params.maxmut, params.order, re.sub('[^/]*/', '', params.tree))\n",
    "\n",
    "# parse fasta alignment \n",
    "dnacodontable = {'ttt':'F', 'ttc':'F', 'tta':'L', 'ttg':'L', 'ctt':'L', 'ctc':'L', 'cta':'L', 'ctg':'L', 'att':'I', 'atc':'I', 'ata':'I', 'atg':'M', 'gtt':'V', 'gtc':'V', 'gta':'V', 'gtg':'V', 'tct':'S', 'tcc':'S', 'tca':'S', 'tcg':'S', 'cct':'P', 'ccc':'P', 'cca':'P', 'ccg':'P', 'act':'T', 'acc':'T', 'aca':'T', 'acg':'T', 'gct':'A', 'gcc':'A', 'gca':'A', 'gcg':'A', 'tat':'Y', 'tac':'Y', 'taa':'stop', 'tag':'stop', 'cat':'H', 'cac':'H', 'caa':'Q', 'cag':'Q', 'aat':'N', 'aac':'N', 'aaa':'K', 'aag':'K', 'gat':'D', 'gac':'D', 'gaa':'E', 'gag':'E', 'tgt':'C', 'tgc':'C', 'tga':'stop', 'tgg':'W', 'cgt':'R', 'cgc':'R', 'cga':'R', 'cgg':'R', 'agt':'S', 'agc':'S', 'aga':'R', 'agg':'R', 'ggt':'G', 'ggc':'G', 'gga':'G', 'ggg':'G'}\n",
    "\n",
    "fdat_nuc = parsefasta(params.aln)\n",
    "fdat_aa = {k:translatedDNA(v) for k,v in fdat_nuc.items()}\n",
    "isolateid_to_fdatheader = {re.search('(GBISL|EPIISL|GB_ISL_|EPI_ISL_)\\d+', header).group().replace('_', ''):header for header in fdat_nuc.keys()}\n",
    "fdatheader_to_isolateid = {v:k for k,v in isolateid_to_fdatheader.items()}\n",
    "isolateid_to_age = {isolateid:int(re.search('AGE(\\d+)', header).group(1)) for isolateid, header in isolateid_to_fdatheader.items()}\n",
    "\n",
    "# sequences to ignore (outside of child_min and adult_max age)\n",
    "isolates_to_ignore = [isolateid for isolateid, age in isolateid_to_age.items() if age < params.child[0] or age > params.adult[-1]]\n",
    "\n",
    "# parse clstr file and sort each identical sequence cluster (>1 member sequence) into children/adult age categories \n",
    "# isolates_to_ignore now include those of ambiguous age categories (between child_max and adult_min) \n",
    "# + 0 pat dist sequences with > minimal number of n/-\n",
    "isolateid_to_representatives, isolateid_to_agecategory = {}, {} \n",
    "fhandle = filter(None, open(params.nr, 'rU').readlines())\n",
    "for key, group in itertools.groupby(fhandle, lambda _: re.search('^>Cluster', _)):\n",
    "    if not key:\n",
    "        cluster = list(group)\n",
    "        if len(cluster) > 1:\n",
    "            cluster = [re.search('(GBISL|EPIISL|GB_ISL_|EPI_ISL_)\\d+', header).group().replace('_', '') for header in cluster]\n",
    "            cluster_age = [isolateid_to_age[isolateid] for isolateid in cluster]\n",
    "            # all children or adults sequence clusters\n",
    "            if all([params.child[0] <= age <= params.child[-1] for age in cluster_age]):\n",
    "                isolateid_to_agecategory[isolateid] = 'C'\n",
    "                for isolateid in cluster:\n",
    "                    isolateid_to_representatives[isolateid] = cluster\n",
    "            elif all([params.adult[0] <= age <= params.adult[-1] for age in cluster_age]):\n",
    "                isolateid_to_agecategory[isolateid] = 'A'\n",
    "                for isolateid in cluster:\n",
    "                    isolateid_to_representatives[isolateid] = cluster\n",
    "            # uncategorized age present in sequence cluster \n",
    "            elif all([params.child[0] <= age <= params.adult[-1] for age in cluster_age]) and any([params.child[-1] < age < params.adult[0] for age in cluster_age]):\n",
    "                isolateid_to_agecategory[isolateid] = 'U'\n",
    "                for isolateid in cluster:\n",
    "                    isolateid_to_representatives[isolateid] = [member for _, member in enumerate(cluster) if params.child[-1] < cluster_age[_] < params.adult[0]]\n",
    "            else:\n",
    "                isolates_to_ignore = list(set(isolates_to_ignore)|set(cluster))\n",
    "\n",
    "# print example\n",
    "example_isolateid = random.choice(isolateid_to_agecategory.keys())\n",
    "print ('EXAMPLE of the age category of a CD-HIT cluster:\\nRepresentative sequence = {}'.format(isolateid_to_fdatheader[example_isolateid]))\n",
    "print ('Age category: {}'.format(isolateid_to_agecategory[example_isolateid]))\n",
    "print ('Member sequences:\\n{}'.format('\\n'.join([isolateid_to_fdatheader[_] for _ in isolateid_to_representatives[example_isolateid]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing phylogenetic tree using ete3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tree = ete3.Tree(params.tree)\n",
    "except:\n",
    "    sys.exit('\\nERROR: Unable to parse tree using ete3.\\n')\n",
    "tree.ladderize()\n",
    "# get nodes to isolate ids\n",
    "leaf_to_isolateid = {leaf:re.search('(EPI_ISL_|EPIISL|GB_ISL_|GBISL)\\d+', leaf.get_leaf_names()[0]).group().replace('_', '') for leaf in tree.get_leaves()}\n",
    "isolateid_to_leaf = {v:k for k,v in leaf_to_isolateid.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing for evolutionarily closest pairs \n",
    "\n",
    "To maximally identify virus pairs with differences while maintaining the evolutionary relatedness between these sequences at the closest level, note that all inferred patrsitic distances were truncated to 4 decimal places to disregard differences attributed to transitions/transversions.\n",
    "\n",
    "Recall that the ML tree was rooted to maximally correlate root-to-tip distance with time. Starting from the root, we traverse the tree by level-order.  \n",
    "\n",
    "1. For each internal node, we parse for the progeny leaf (tip) closest to the node, with the least number of unknown residues, as the ancestral sequence(s). Note that there CAN be >1 ancestral sequence.\n",
    "2. Gather the rest of the progeny leaves as well as the grand-children leaves of the current internal node. \n",
    "3. Order the progeny and grand-children leaves by their patristic distance to node. \n",
    "4. Combinatorially, pair each of the progeny/grand-children leaf to the ancestral sequence(s) up to the stipulated order (in this case params.order = 3).\n",
    "\n",
    "Note that certain sequences/pairs are omitted if: \n",
    "1. the sequence is part of the CD-HIT identical nucleotide sequence cluster age-categorized as [U]ncategorized \n",
    "2. the sequence pair resulted in >params.maxmut (5 in this case) amino acid changes. \n",
    "3. the patristic distance between the paired sequences is >params.patdist (0.007 in this case). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_to_desc = {}\n",
    "desc_to_anc = {}\n",
    "pair_to_subinfo = {}\n",
    "pair_to_pwdist = {}\n",
    "# traverse through tree level-order\n",
    "for node in tree.traverse():\n",
    "    if node.is_leaf():\n",
    "        continue\n",
    "\n",
    "    # get children leaf nodes and their distances to current node\n",
    "    childleaf_to_distance = {child:Decimal(child.get_distance(node)).quantize(Decimal('1e-4')) for child in node.children if child.is_leaf()}\n",
    "\n",
    "    if len(childleaf_to_distance) > 0:\n",
    "        # closest child leaf(s) from node - decide closest child leaf using patristic distances without truncating at 1e-5\n",
    "        nearest_childleaf = [child for child in childleaf_to_distance.keys() if childleaf_to_distance[child] == min(childleaf_to_distance.values())]\n",
    "        # remove sequences in cases where distance = 0 and aren't the least number of unknown residues\n",
    "        if min(childleaf_to_distance.values()) == 0 and len(nearest_childleaf) > 1:\n",
    "            nearest_childleaf, childleaf_to_distance = get_least_unknown_residue_sequences({child:fdat_nuc[isolateid_to_fdatheader[leaf_to_isolateid[child]]] for child in nearest_childleaf}, dist_dict_to_edit=childleaf_to_distance)\n",
    "\n",
    "        # define nearest child leaf/leaves\n",
    "        nearest_childleaf_distance_to_node = {child:childleaf_to_distance[child] for child in nearest_childleaf}\n",
    "        for child in nearest_childleaf:\n",
    "            del childleaf_to_distance[child]\n",
    "\n",
    "        # get (great0-)^n-grandchildren leaves\n",
    "        descendant_internal_nodes = [child for child in node.get_descendants() if not child.is_leaf() and node.get_distance(child) < params.patdist]\n",
    "        if len(descendant_internal_nodes) > 0:\n",
    "            for childnode in descendant_internal_nodes:\n",
    "                grandchildren_leaves = [grandchild for grandchild in childnode.children if grandchild.is_leaf()]\n",
    "                if len(grandchildren_leaves) > 0:\n",
    "                    grandchildleaf_to_distance = {grandchild:Decimal(grandchild.get_distance(childnode)).quantize(Decimal('1e-4')) for grandchild in grandchildren_leaves}\n",
    "                    nearest_grandchild_with_zero_distance = [grandchild for grandchild in grandchildren_leaves if grandchildleaf_to_distance[grandchild] == 0]\n",
    "                    # remove sequences in cases where distance = 0 and aren't the least number of unknown residues\n",
    "                    # we do this because we don't want to re-count possible identical strains\n",
    "                    if len(nearest_grandchild_with_zero_distance) > 1:\n",
    "                        nearest_grandchild_with_zero_distance_to_keep = get_least_unknown_residue_sequences({grandchild:fdat_nuc[isolateid_to_fdatheader[leaf_to_isolateid[grandchild]]] for grandchild in nearest_grandchild_with_zero_distance})\n",
    "                        for grandchild in list(set(nearest_grandchild_with_zero_distance)-set(nearest_grandchild_with_zero_distance_to_keep)):\n",
    "                            grandchildren_leaves.remove(grandchild)\n",
    "                    # update grandchild distance to node\n",
    "                    childleaf_to_distance.update({grandchild:Decimal(grandchild.get_distance(node)).quantize(Decimal('1e-4')) for grandchild in grandchildren_leaves})\n",
    "\n",
    "        # if there are no children/grandchildren left for pairing\n",
    "        if len(childleaf_to_distance) == 0:\n",
    "            continue\n",
    "\n",
    "        for anc_leaf in nearest_childleaf:\n",
    "            # ignore ambiguous age isolates\n",
    "            anc = leaf_to_isolateid[anc_leaf]\n",
    "            if anc in isolates_to_ignore:\n",
    "                continue\n",
    "\n",
    "            # find closest pairing descendants\n",
    "            # get pairwise distance to ancestor\n",
    "            childleaf_to_pwdistance = {}\n",
    "            for child, distance in childleaf_to_distance.items():\n",
    "                pwdistance = nearest_childleaf_distance_to_node[anc_leaf] + distance\n",
    "                childleaf_to_pwdistance[child] = pwdistance\n",
    "                pair_to_pwdist[(anc, leaf_to_isolateid[child])] = pwdistance\n",
    "\n",
    "            # analyze up to the n-th order set of pairs\n",
    "            for pwdistance in sorted(set(childleaf_to_pwdistance.values()))[:params.order]:\n",
    "                # patristic distance threshold\n",
    "                if pwdistance > params.patdist:\n",
    "                    continue\n",
    "\n",
    "                children_with_distance = [child for child, child_distance in childleaf_to_pwdistance.items() if child_distance == pwdistance]\n",
    "                for desc_leaf in children_with_distance:\n",
    "\n",
    "                    desc = leaf_to_isolateid[desc_leaf]\n",
    "                    if desc in isolates_to_ignore:\n",
    "                        continue\n",
    "\n",
    "                    # descendant should be further away from node\n",
    "                    if childleaf_to_distance[desc_leaf] <= nearest_childleaf_distance_to_node[anc_leaf]:\n",
    "                        continue\n",
    "\n",
    "                    substitutions = get_pairwise_substitutions(fdat_aa[isolateid_to_fdatheader[anc]], fdat_aa[isolateid_to_fdatheader[desc]])\n",
    "                    # amino acid substitutions threshold\n",
    "                    if len(substitutions) > params.maxmut:\n",
    "                        continue\n",
    "\n",
    "                    # check that there is no nearer ancestor to descendant\n",
    "                    if desc in desc_to_anc:\n",
    "                        prev_anc_list = desc_to_anc[desc]\n",
    "                        prev_anc_to_pwdist = {prev_anc:pair_to_pwdist[(prev_anc, desc)] for prev_anc in prev_anc_list}\n",
    "                        prev_anc_to_pwdist[anc] = pwdistance\n",
    "                        minimum_distance = min(prev_anc_to_pwdist.values())\n",
    "\n",
    "                        for prev_anc, prev_anc_pwdist in prev_anc_to_pwdist.items():\n",
    "                            if prev_anc_pwdist == minimum_distance:\n",
    "                                if prev_anc in anc_to_desc:\n",
    "                                    if desc not in anc_to_desc[prev_anc]:\n",
    "                                        anc_to_desc[prev_anc].append(desc)\n",
    "                                else:\n",
    "                                    anc_to_desc[prev_anc] = [desc]\n",
    "\n",
    "                                if desc in desc_to_anc:\n",
    "                                    if prev_anc not in desc_to_anc[desc]:\n",
    "                                        desc_to_anc[desc].append(prev_anc)\n",
    "                                else:\n",
    "                                    desc_to_anc[desc] = [prev_anc]\n",
    "\n",
    "                                if (prev_anc, desc) not in pair_to_subinfo:\n",
    "                                    pair_to_subinfo[(prev_anc, desc)] = (substitutions, get_pairwise_substitutions(fdat_nuc[isolateid_to_fdatheader[anc]], fdat_nuc[isolateid_to_fdatheader[desc]]))\n",
    "                            else:\n",
    "                                try:\n",
    "                                    anc_to_desc[prev_anc].remove(desc)\n",
    "                                    if len(anc_to_desc[prev_anc]) == 0:\n",
    "                                        del anc_to_desc[prev_anc]\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "                                try:\n",
    "                                    desc_to_anc[desc].remove(prev_anc)\n",
    "                                    if len(desc_to_anc[desc]) == 0:\n",
    "                                        del desc_to_anc[desc]\n",
    "                                except:\n",
    "                                    pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            anc_to_desc[anc].append(desc)\n",
    "                        except:\n",
    "                            anc_to_desc[anc] = [desc]\n",
    "\n",
    "                        try:\n",
    "                            desc_to_anc[desc].append(anc)\n",
    "                        except:\n",
    "                            desc_to_anc[desc] = [anc]\n",
    "\n",
    "                        pair_to_subinfo[(anc, desc)] = (substitutions, get_pairwise_substitutions(fdat_nuc[isolateid_to_fdatheader[anc]], fdat_nuc[isolateid_to_fdatheader[desc]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing output \n",
    "\n",
    "Evolutionarily closest pairs are printed as a tab-delimited output (found in the [Files](https://github.com/alvinxhan/ageflu/tree/master/files) folder as ageflu_evol-closest-pairs.0C5_35A120_PD0.007_MM5_CL3_H3N2-HA-nuc.rooted.nwk.txt under [H3N2](https://github.com/alvinxhan/ageflu/tree/master/files/H3N2)): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get reference numbering \n",
    "ref_subtype_dictionary = {'H1N1PDM09':'H1', 'H3N2':'H3', 'BVIC':'B73', 'BYAM':'B73'}\n",
    "HA_ref_numbering_fdat = parsefasta('./files/H1pdm09_H3_FluB_NumberingRef.fa', check_dna=0, check_codon=0)\n",
    "queryST_to_refST_to_AbNum_to_RefNum = {'H1N1PDM09': {'H1':{}, 'H3':{}, 'B73':{}}, 'H3N2': {'H1':{}, 'H3':{}, 'B73':{}}, 'BVIC': {'H1':{}, 'H3':{}, 'B73':{}}, 'BYAM': {'H1':{}, 'H3':{}, 'B73':{}}}\n",
    "queryST_to_RefStrain = {'H1N1PDM09':'A/Texas/04/2009(H1N1)_H1pdm09absolutenumbering', 'H3N2':'A/Aichi/2/1968(H3N2)_H3absolutenumbering', 'BVIC':'B/Brisbane/60/2008_BVicAbs', 'BYAM':'B/Phuket/3073/2013_BYamAbs'}\n",
    "RefStrain_to_RefSeq = {'H1':HA_ref_numbering_fdat['A/Texas/04/2009(H1N1)_H1pdm09absolutenumbering'], 'H3':HA_ref_numbering_fdat['A/Aichi/2/68(H3N2)_H3numbering'], 'B73':HA_ref_numbering_fdat['B/HK/8/73_BYamNumbering']}\n",
    "FluB_insertion_querypos_to_refpos = {177:162.1, 178:162.2, 179:162.3}\n",
    "\n",
    "for subtype in queryST_to_RefStrain.keys():\n",
    "    for RefStrain, RefSeq in RefStrain_to_RefSeq.items():\n",
    "        CurrRefPosNum, CurrQueryPosNum = 0, 0\n",
    "        for _ in xrange(len(RefSeq)):\n",
    "            RecordPosBIN = -1\n",
    "            if RefSeq[_] != '-':\n",
    "                CurrRefPosNum += 1\n",
    "                RecordPosBIN += 1\n",
    "            if HA_ref_numbering_fdat[queryST_to_RefStrain[subtype]][_] != '-':\n",
    "                CurrQueryPosNum += 1\n",
    "                RecordPosBIN += 1\n",
    "            if RecordPosBIN > 0:\n",
    "                queryST_to_refST_to_AbNum_to_RefNum[subtype][RefStrain][CurrQueryPosNum] = CurrRefPosNum\n",
    "            #162-163 insertion for Flu B (162.1, 162.2, 162.3)\n",
    "            if (subtype == 'BVIC' or subtype == 'BYAM') and _ in range(177,180):\n",
    "                if HA_ref_numbering_fdat[queryST_to_RefStrain[subtype]][_] != '-':\n",
    "                    queryST_to_refST_to_AbNum_to_RefNum[subtype][RefStrain][CurrQueryPosNum] = FluB_insertion_querypos_to_refpos[_]\n",
    "\n",
    "# print output \n",
    "with open('./files/{}/ageflu_evol-closest-pairs.{}.txt'.format(subtype_to_analyse, outfname), 'w') as output:\n",
    "    output.write('pair_type\\tanc\\tdesc\\tmutation(ABS)\\tmutation(REF)\\n')\n",
    "    for anc, desclist in anc_to_desc.items():\n",
    "        for desc in desclist:\n",
    "\n",
    "            # determine pair type\n",
    "            if params.child[0] <= isolateid_to_age[anc] <= params.child[-1]:\n",
    "                anc_age_type = 'C'\n",
    "            elif params.adult[0] <= isolateid_to_age[anc] <= params.adult[-1]:\n",
    "                anc_age_type = 'A'\n",
    "            else:\n",
    "                anc_age_type = 'N'\n",
    "\n",
    "            if params.child[0] <= isolateid_to_age[desc] <= params.child[-1]:\n",
    "                desc_age_type = 'C'\n",
    "            elif params.adult[0] <= isolateid_to_age[desc] <= params.adult[-1]:\n",
    "                desc_age_type = 'A'\n",
    "            else:\n",
    "                desc_age_type = 'N'\n",
    "\n",
    "            if anc_age_type == 'N' or desc_age_type == 'N':\n",
    "                pair_age_type = 'NC'\n",
    "            else:\n",
    "                pair_age_type = '{}{}'.format(anc_age_type, desc_age_type)\n",
    "\n",
    "            # get substitution info\n",
    "            substitutions, nuc_sub_info = pair_to_subinfo[(anc, desc)]\n",
    "            substitutions_abs_positions = [int(re.search('\\d+', _).group()) for _ in substitutions]\n",
    "\n",
    "            # get reference positions\n",
    "            substitutions_ref_positions = [queryST_to_refST_to_AbNum_to_RefNum[query_subtype][ref_subtype_dictionary[query_subtype]][abs_pos] if abs_pos in queryST_to_refST_to_AbNum_to_RefNum[query_subtype][ref_subtype_dictionary[query_subtype]] else '-' for abs_pos in substitutions_abs_positions]\n",
    "\n",
    "            # write to output\n",
    "            write_line = map(str, [pair_age_type, isolateid_to_fdatheader[anc], isolateid_to_fdatheader[desc], ','.join(substitutions), ','.join(map(str, substitutions_ref_positions))])\n",
    "            output.write('{}\\n'.format('\\t'.join(write_line)))\n",
    "            output.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age-association analyses \n",
    "\n",
    "With the evolutionarily closest pairs of sequences, we now perform the following age-association analyses. You can do so using [ageflu_analysis.py](https://github.com/alvinxhan/ageflu/blob/master/scripts/ageflu_analysis.py). Here, we show the breakdown of the script.\n",
    "\n",
    "### Importing modules and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "import subprocess, numpy\n",
    "\n",
    "# check for N-X-S/T glycosylation motif changes\n",
    "def check_glyco(positions, anc_seq, desc_seq):\n",
    "    glyco_sites = []\n",
    "    for pos in positions:\n",
    "        if anc_seq[pos-1] == 'N' and re.search('N[^PX-][ST]', anc_seq[pos-1:pos+2]) and not re.search('N[^PX-][ST]', desc_seq[pos-1:pos+2]):\n",
    "            glyco_sites.append(pos)\n",
    "        elif re.search('[^PX-]', anc_seq[pos-1]) and re.search('N[^PX-][ST]', anc_seq[pos-2:pos+1]) and not re.search('N[^PX-][ST]', desc_seq[pos-2:pos+1]):\n",
    "            glyco_sites.append(pos)\n",
    "        elif re.search('[ST]', anc_seq[pos-1]) and re.search('N[^PX-][ST]', anc_seq[pos-3:pos]) and not re.search('N[^PX-][ST]', desc_seq[pos-3:pos]):\n",
    "            glyco_sites.append(pos)\n",
    "\n",
    "    return glyco_sites\n",
    "\n",
    "# odds ratio analyses using R (called using subprocess)\n",
    "def calculateOR(n11, n10, n01, n00):\n",
    "\n",
    "    ORnum = n11*n00\n",
    "    ORden = n01*n10\n",
    "\n",
    "    if ORnum == ORden == 0:\n",
    "        OR_uMLE, wald_MLE_CI95L, wald_MLE_CI95R = 'NaN', '', ''\n",
    "        wald_MLE_CI90L, wald_MLE_CI90R = '', ''\n",
    "    elif ORnum == 0:\n",
    "        OR_uMLE, wald_MLE_CI95L, wald_MLE_CI95R = 0, '', ''\n",
    "        wald_MLE_CI90L, wald_MLE_CI90R = '', ''\n",
    "    elif ORden == 0:\n",
    "        OR_uMLE, wald_MLE_CI95L, wald_MLE_CI95R = 'InF', '', ''\n",
    "        wald_MLE_CI90L, wald_MLE_CI90R = '', ''\n",
    "    else:\n",
    "        OR_uMLE = ORnum/ORden\n",
    "        # Wald test & CI\n",
    "        lnOR = numpy.log(OR_uMLE)\n",
    "        SE_lnOR = numpy.sqrt(sum(map(lambda _:1/_ ,[n11,n10,n01,n00])))\n",
    "        wald_MLE_CI95L, wald_MLE_CI95R =  numpy.exp(lnOR - 1.96*SE_lnOR), numpy.exp(lnOR + 1.96*SE_lnOR)\n",
    "        wald_MLE_CI90L, wald_MLE_CI90R =  numpy.exp(lnOR - 1.645*SE_lnOR), numpy.exp(lnOR + 1.645*SE_lnOR)\n",
    "\n",
    "    if n11 + n10 + n01 + n00 >= 1000:\n",
    "        # G-test\n",
    "        cmd = ['Rscript', \"./scripts/ageflu_gtest.R\"] + map(str,[n11, n10, n01, n00])\n",
    "        Routput = subprocess.check_output(cmd, universal_newlines=True, stderr=subprocess.PIPE).split('\\n')\n",
    "        pval = float(Routput[1])\n",
    "        # small sample size CI - NaN\n",
    "        ss_CI90L, ss_CI90R, ss_CI95L, ss_CI95R = 'NaN', 'NaN', 'NaN', 'NaN'\n",
    "    else:\n",
    "        # Barnard's\n",
    "        cmd = ['Rscript', \"./scripts/ageflu_barnard.R\"] + map(str,[n11, n10, n01, n00])\n",
    "        Routput = subprocess.check_output(cmd, universal_newlines=True, stderr=subprocess.PIPE).split('\\n')\n",
    "        pval = float(Routput[-2].replace('[1]','').split()[1])\n",
    "        # Agresti & Min unconditional exact CI for small sample sizes\n",
    "        cmd = ['Rscript', \"./scripts/agresti_and_min.R\"] + map(str,[n11, n10, n01, n00, 0.9])\n",
    "        Routput = filter(None, subprocess.check_output(cmd, universal_newlines=True, stderr=subprocess.PIPE).split('\\n'))\n",
    "        ss_CI90L, ss_CI90R = map(lambda _: _ if _ == 'Inf' else float(_), re.findall('(\\d+\\.\\d+|\\d+|Inf)', Routput[-1]))\n",
    "\n",
    "        cmd = ['Rscript', \"./scripts/agresti_and_min.R\"] + map(str,[n11, n10, n01, n00, 0.95])\n",
    "        Routput = filter(None, subprocess.check_output(cmd, universal_newlines=True, stderr=subprocess.PIPE).split('\\n'))\n",
    "        ss_CI95L, ss_CI95R = map(lambda _: _ if _ == 'Inf' else float(_), re.findall('(\\d+\\.\\d+|\\d+|Inf)', Routput[-1]))\n",
    "\n",
    "    return OR_uMLE, wald_MLE_CI90L, wald_MLE_CI90R, wald_MLE_CI95L, wald_MLE_CI95R, pval, ss_CI90L, ss_CI90R, ss_CI95L, ss_CI95R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./files/H3N2/ageflu_evol-closest-pairs.0C5_35A120_PD0.007_MM5_CL3_H3N2-HA-nuc_rooted.nwk.txt\n"
     ]
    }
   ],
   "source": [
    "if passage_requirement == 'F':\n",
    "    class params():\n",
    "        input_file = './files/{st}/ageflu_evol-closest-pairs.0C{child_max_age}_{adult_min_age}A120_PD0.007_MM5_CL3_{st}-HA-nuc_rooted.nwk.txt'.format(st=subtype_to_analyse, \n",
    "                                                                                                                                                      child_max_age=subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['child'][-1],\n",
    "                                                                                                                                                      adult_min_age=subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['adult'][0]) # ageflu_getpairs.py output\n",
    "        aln = './files/{st}/{st}-HA-nuc.fa'.format(st=subtype_to_analyse) # Nucleotide alignment of HA sequences (pre-CD-HIT)\n",
    "        same_passage = False # binary whether to implement filter to only analyse sequence pairs derived from the same passage type \n",
    "else:\n",
    "    class params():\n",
    "        input_file = './files/{st}/ageflu_evol-closest-pairs.0C{child_max_age}_{adult_min_age}A120_PD0.007_MM5_CL3_{st}-HA-nuc_rooted.nwk.txt'.format(st=subtype_to_analyse, \n",
    "                                                                                                                                                      child_max_age=subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['child'][-1],\n",
    "                                                                                                                                                      adult_min_age=subtype_to_passage_to_age_range[passage_requirement][subtype_to_analyse]['adult'][0]) # ageflu_getpairs.py output\n",
    "        aln = './files/{st}/{st}-HA-nuc.fa'.format(st=subtype_to_analyse) # Nucleotide alignment of HA sequences (pre-CD-HIT)\n",
    "        same_passage = True #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters - Known canonical antigenic/receptor-binding sites + reference positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### POSITION PARAMETERS - FluA (all based on H3 numbering)###\n",
    "# antigenic sites gathered from Stray, S. J., & Pittman, L. B. (2012). Subtype-and antigenic site-specific differences in biophysical influences on evolution of influenza virus hemagglutinin. Virology journal, 9(1), 1.\n",
    "H3ant = {\"A\": range(121,130) + range(131,139) + range(142,147)  + [140],\n",
    "         \"B\": range(155,161) + range(188,191) + range(192,195) + range(196,200) + [186, 246, 247],\n",
    "         \"C\": [49, 50, 53, 54, 271, 273, 275, 276, 278],\n",
    "         \"D\": range(201,208) + range(216, 221) + range(225, 228) + [167, 214, 222, 223, 242],\n",
    "         \"E\": range(79, 84) + [62, 63, 75, 78, 91, 92]}\n",
    "\n",
    "H1ant = {\"Sa\": range(165,168) + [128, 129, 163, 247, 248],\n",
    "         \"Sb\": [156, 159, 189, 190, 192, 193, 196, 197, 198],\n",
    "         \"Ca1\": range(240, 246) + [169, 173, 207, 212],\n",
    "         \"Ca2\": [132, 140, 143, 144, 145, 149, 224, 225],\n",
    "         \"Cb\": range(259, 266) + [56, 79, 80, 82, 83, 117, 149, 255, 256],\n",
    "         \"H1C\": range(271, 277) + range(278, 282) + [90, 285]}\n",
    "\n",
    "# H3 rbs gathered from Yang, H., Carney, P. J., Chang, J. C., Guo, Z., Villanueva, J. M., & Stevens, J. (2015). Structure and receptor binding preferences of recombinant human A (H3N2) virus hemagglutinins. Virology, 477, 18-31 - based on H3 numbering\n",
    "H3RBS = [98, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 144, 145, 146, 153, 154, 155, 156, 157, 158, 159, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196] + range(219,229)\n",
    "\n",
    "#passage sites - based on H3 numbering\n",
    "weiwei22pas = [111, 126, 137, 138, 144, 145, 155, 156, 158, 159, 185, 186, 193, 194, 199, 219, 226, 229, 246, 248, 276, 290]\n",
    "RaphaelPas = [13, 96, 137, 156, 183, 186, 189, 190, 193, 194, 196, 203, 219, 222, 246, 248, 328, 332, 335, 337, 352, 353, 376, 447, 465, 504, 515]\n",
    "SebastianPas = [101, 103, 123, 129, 131, 133, 137, 140, 142, 144, 145, 156, 157, 158, 159, 165, 187, 188, 192, 193, 196, 197, 198, 218, 222, 225, 226, 227, 252, 262, 269, 273, 279, 312, 474, 476, 498, 45, 510, 529, 48]\n",
    "\n",
    "### POSITION PARAMETERS - Flu B (all based on B/HK/8/73 numbering)###\n",
    "FluB_insertion_querypos_to_refpos = {177:162.1, 178:162.2, 179:162.3}\n",
    "FluBant = {\"120loop\":range(51,55) + range(56,60)+range(73,76)+range(121,124)+range(179,182)+range(283,286)+[129,137],\n",
    "           \"150loop\":range(139,143) + range(145,152),\n",
    "           \"160loop\":range(162,166) + range(167,172),\n",
    "           \"190helix\":range(194,201) + range(235,241)+[205],\n",
    "           \"162-163insertion\":[162.1, 162.2, 162.3]}\n",
    "FluBRBS = range(193,203) + range(237,243) + range(136,144) + [95, 158, 191, 202]\n",
    "\n",
    "\n",
    "if query_subtype == 'H3N2':\n",
    "    AS_dict, RBS_list = H3ant, H3RBS\n",
    "elif query_subtype == 'H1N1PDM09':\n",
    "    AS_dict, RBS_list = H1ant, H3RBS\n",
    "else:\n",
    "    AS_dict, RBS_list = FluBant, FluBRBS\n",
    "# AS + RBS\n",
    "functional_sites = list(set(RBS_list)|set([k for v in AS_dict.values() for k in v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse input files and count pairs/substitution frequencies \n",
    "\n",
    "We first parse the input files and count the number of pairs for each pair-type and their corresponding amino acid substitution frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read fasta file\n",
    "fdat_nuc = parsefasta(params.aln)\n",
    "fdat_aa = {k:translatedDNA(v) for k,v in fdat_nuc.items()}\n",
    "header_to_passage = {header:re.search('(ORI|MDCK|SIAT|EGG)', header).group() for header in fdat_nuc.keys()}\n",
    "\n",
    "# read input file and count pairs/substitutions\n",
    "pt_count, pt_to_AAsublen, pt_to_RBASsub, abspos_to_pt_to_count, abspos_to_mutation_to_pt_to_count, abspos_to_refpos = {}, {}, {}, {}, {}, {}\n",
    "all_potential_glycosylation_sites = []\n",
    "\n",
    "fhandle = filter(None, open(params.input_file, 'rU'))\n",
    "fhandle.pop(0)\n",
    "for line in fhandle:\n",
    "    try:\n",
    "        pt, anc, desc, substitutions, substitutions_ref_positions = line.strip().split('\\t')\n",
    "        substitutions = substitutions.split(',')\n",
    "    except:\n",
    "        pt, anc, desc = line.strip().split('\\t')\n",
    "        substitutions = []\n",
    "\n",
    "    # same passage filter\n",
    "    if params.same_passage and header_to_passage[anc] != header_to_passage[desc]:\n",
    "        continue\n",
    "\n",
    "    # add to pair type count\n",
    "    try:\n",
    "        pt_count[pt] += 1\n",
    "    except:\n",
    "        pt_count[pt] = 1\n",
    "\n",
    "    # add to pair type substitution count\n",
    "    try:\n",
    "        pt_to_AAsublen[pt][len(substitutions)] += 1\n",
    "    except:\n",
    "        try:\n",
    "            pt_to_AAsublen[pt][len(substitutions)] = 1\n",
    "        except:\n",
    "            pt_to_AAsublen[pt] = {len(substitutions):1}\n",
    "\n",
    "    # continue if NC pairs\n",
    "    if pt == 'NC':\n",
    "        continue\n",
    "\n",
    "    if len(substitutions) > 0:\n",
    "        # check if any substitutions are potential glycosylation sites\n",
    "        substitutions_abs_positions = [int(re.search('\\d+', _).group()) for _ in substitutions]\n",
    "        potential_glycosylation_sites = check_glyco(substitutions_abs_positions, fdat_aa[anc], fdat_aa[desc])\n",
    "        all_potential_glycosylation_sites = list(set(all_potential_glycosylation_sites)|set(potential_glycosylation_sites))\n",
    "\n",
    "\n",
    "        for p, abs_pos in enumerate(substitutions_abs_positions):\n",
    "            # add to position substitution count\n",
    "            try:\n",
    "                abspos_to_pt_to_count[abs_pos][pt] += 1\n",
    "            except:\n",
    "                try:\n",
    "                    abspos_to_pt_to_count[abs_pos][pt] = 1\n",
    "                except:\n",
    "                    abspos_to_pt_to_count[abs_pos] = {pt:1}\n",
    "\n",
    "            # add to pos-mutation dictionary\n",
    "            substitution = substitutions[p]\n",
    "            try:\n",
    "                abspos_to_mutation_to_pt_to_count[abs_pos][substitution][pt] += 1\n",
    "            except:\n",
    "                try:\n",
    "                    abspos_to_mutation_to_pt_to_count[abs_pos][substitution][pt] = 1\n",
    "                except:\n",
    "                    try:\n",
    "                        abspos_to_mutation_to_pt_to_count[abs_pos][substitution] = {pt:1}\n",
    "                    except:\n",
    "                        abspos_to_mutation_to_pt_to_count[abs_pos] = {substitution:{pt:1}}\n",
    "\n",
    "        # count if any sites are either RBS/AS\n",
    "        ref_positions = []\n",
    "        for _ in substitutions_ref_positions.split(','):\n",
    "            if _ == '-':\n",
    "                ref_positions.append('-')\n",
    "            elif re.search('162(\\.1|\\.2|\\.3)', _):\n",
    "                ref_positions.append(float(_))\n",
    "            else:\n",
    "                ref_positions.append(int(_))\n",
    "        for _, refpos in enumerate(ref_positions):\n",
    "            abspos_to_refpos[substitutions_abs_positions[_]] = refpos\n",
    "\n",
    "        if set(functional_sites)&set(ref_positions):\n",
    "            try:\n",
    "                pt_to_RBASsub[pt] += 1\n",
    "            except:\n",
    "                pt_to_RBASsub[pt] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pairs distribution analyses\n",
    "\n",
    "### Print distribution of pairs stratified by number/proportion of amino acid substitutions\n",
    "\n",
    "We generate the output file (in this case, ageflu_pairs-distribution.0C5_35A120_PD0.007_MM5_CL3_H3N2-HA-nuc_rooted.nwk_SP0.txt). First, we print the distribution of pairs stratified by the number/proportion of amino acid substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxmut = int(re.search('_MM(\\d+)_', params.input_file).group(1))\n",
    "outfname = '{}_SP{}.txt'.format(re.sub('/*[^/]+/', '', params.input_file.replace('ageflu_evol-closest-pairs.', '').replace('.txt', '')), '1' if params.same_passage else '0')\n",
    "\n",
    "# write to output\n",
    "output = open('ageflu_pairs-distribution.{}'.format(outfname), 'w')\n",
    "\n",
    "# pair distribution - frequencies\n",
    "output.write('Frequency distribution of pair types stratified by number of amino acid substitutions\\nPT/Sub_#\\tCA\\tAC\\tCC\\tAA\\tNC\\tSub#_TOT\\n')\n",
    "col_counts = [0]*(maxmut)\n",
    "sublen_to_row_counts = {}\n",
    "for sub_len in xrange(maxmut+1):\n",
    "    try:\n",
    "        CA_count = pt_to_AAsublen['CA'][sub_len]\n",
    "    except:\n",
    "        CA_count = 0\n",
    "        try:\n",
    "            pt_to_AAsublen['CA'][sub_len] = 0\n",
    "        except:\n",
    "            pt_to_AAsublen['CA']={sub_len:0}\n",
    "\n",
    "    try:\n",
    "        AC_count = pt_to_AAsublen['AC'][sub_len]\n",
    "    except:\n",
    "        AC_count = 0\n",
    "        try:\n",
    "            pt_to_AAsublen['AC'][sub_len] = 0\n",
    "        except:\n",
    "            pt_to_AAsublen['AC'] = {sub_len: 0}\n",
    "\n",
    "    try:\n",
    "        CC_count = pt_to_AAsublen['CC'][sub_len]\n",
    "    except:\n",
    "        CC_count = 0\n",
    "        try:\n",
    "            pt_to_AAsublen['CC'][sub_len] = 0\n",
    "        except:\n",
    "            pt_to_AAsublen['CC'] = {sub_len: 0}\n",
    "\n",
    "    try:\n",
    "        AA_count = pt_to_AAsublen['AA'][sub_len]\n",
    "    except:\n",
    "        AA_count = 0\n",
    "        try:\n",
    "            pt_to_AAsublen['AA'][sub_len] = 0\n",
    "        except:\n",
    "            pt_to_AAsublen['AA'] = {sub_len: 0}\n",
    "\n",
    "    try:\n",
    "        NC_count = pt_to_AAsublen['NC'][sub_len]\n",
    "    except:\n",
    "        NC_count = 0\n",
    "        try:\n",
    "            pt_to_AAsublen['NC'][sub_len] = 0\n",
    "        except:\n",
    "            pt_to_AAsublen['NC'] = {sub_len: 0}\n",
    "\n",
    "    row_counts = [CA_count, AC_count, CC_count, AA_count, NC_count]\n",
    "    sublen_to_row_counts[sub_len] = row_counts\n",
    "\n",
    "    for k, count in enumerate(row_counts):\n",
    "        col_counts[k] += count\n",
    "    output.write('{}\\t{}\\t{}\\n'.format(sub_len, '\\t'.join(map(str, row_counts)), sum(row_counts)))\n",
    "output.write('PT_TOT\\t{}\\t\\n\\n'.format('\\t'.join(map(str, col_counts))))\n",
    "\n",
    "# pairs distribution - proportions\n",
    "output.write('Distribution of pair types stratified by number of amino acid substitutions\\nPT/Sub_#\\tCA\\tAC\\tCC\\tAA\\tNC\\n')\n",
    "for sub_len in xrange(maxmut+1):\n",
    "    div_list = [ ]\n",
    "    for k, col_tot in enumerate(col_counts):\n",
    "        try:\n",
    "            div_list.append(sublen_to_row_counts[sub_len][k]/col_tot)\n",
    "        except:\n",
    "            div_list.append('NaN')\n",
    "\n",
    "    output.write('{}\\t{}\\n'.format(sub_len, '\\t'.join(map(lambda _: '{}'.format(_), div_list))))\n",
    "output.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association analyses between pair types (end-in-adult v. end-in-child) and observation for substitution(s) - whole HA protein\n",
    "\n",
    "Next, we perform two-way contingency table analyses between pair types (end-in-adult (CA/AA) pairs vs. end-in-child (CC/AC) pairs) and if changes between the paired sequences were observed. Here, we consider substitutions across the entire HA protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    n1t = pt_count['CA']\n",
    "except:\n",
    "    n1t = 0\n",
    "\n",
    "try:\n",
    "    n1t += pt_count['AA']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    n0t = pt_count['CC']\n",
    "except:\n",
    "    n0t = 0\n",
    "\n",
    "try:\n",
    "    n0t += pt_count['AC']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    n11 = sum([pt_to_AAsublen['CA'][_] for _ in pt_to_AAsublen['CA'] if _ > 0])\n",
    "except:\n",
    "    n11 = 0\n",
    "\n",
    "try:\n",
    "    n11 += sum([pt_to_AAsublen['AA'][_] for _ in pt_to_AAsublen['AA'] if _ > 0])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    n01 = sum([pt_to_AAsublen['CC'][_] for _ in pt_to_AAsublen['CC'] if _ > 0])\n",
    "except:\n",
    "    n01 = 0\n",
    "\n",
    "try:\n",
    "    n01 += sum([pt_to_AAsublen['AC'][_] for _ in pt_to_AAsublen['AC'] if _ > 0])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "output.write('Association analyses between pair-type (end-in-adult v. end-in-child) and propensity for substitution(s) - whole HA\\nPT/SF\\tSubstitution\\tNo Substitution\\nEnd-in-Adult\\t{}\\t{}\\nEnd-in-Child\\t{}\\t{}\\n'.format(n11, n1t-n11, n01, n0t-n01))\n",
    "OR_uMLE, wald_MLE_CI90L, wald_MLE_CI90R, wald_MLE_CI95L, wald_MLE_CI95R, pval, ss_CI90L, ss_CI90R, ss_CI95L, ss_CI95R = calculateOR(n11, n1t-n11, n01, n0t-n01)\n",
    "output.write('OR\\t{}\\tp-value\\t{}\\nWald_95CI\\t{}\\nWald_90CI\\t{}\\nA&M_90CI\\t{}\\nA&M_95CI\\t{}\\n\\n'.format(OR_uMLE, pval, ','.join(map(lambda _: '{}'.format(_), [wald_MLE_CI90L, wald_MLE_CI90R])), ','.join(map(lambda _: '{}'.format(_), [wald_MLE_CI95L, wald_MLE_CI95R])), ','.join(map(lambda _: '{}'.format(_), [ss_CI90L, ss_CI90R])), ','.join(map(lambda _: '{}'.format(_), [ss_CI95L, ss_CI95R]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association analyses between pair types (end-in-adult v. end-in-child) and observation for substitution(s) - RBS/AS only\n",
    "\n",
    "Next, we perform the same association analysis but only consider substitutions within the receptor-binding/antigenic regions only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n1t and n0t stays the same\n",
    "try:\n",
    "    n11 = pt_to_RBASsub['CA']\n",
    "except:\n",
    "    n11 = 0\n",
    "\n",
    "try:\n",
    "    n11 += pt_to_RBASsub['AA']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    n01 = pt_to_RBASsub['CC']\n",
    "except:\n",
    "    n01 = 0\n",
    "\n",
    "try:\n",
    "    n01 += pt_to_RBASsub['AC']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "output.write('Association analyses between pair-type (end-in-adult v. end-in-child) and propensity for substitution(s) - RBS/AS\\nPT/SF\\tSubstitution\\tNo Substitution\\nEnd-in-Adult\\t{}\\t{}\\nEnd-in-Child\\t{}\\t{}\\n'.format(n11, n1t-n11, n01, n0t-n01))\n",
    "OR_uMLE, wald_MLE_CI90L, wald_MLE_CI90R, wald_MLE_CI95L, wald_MLE_CI95R, pval, ss_CI90L, ss_CI90R, ss_CI95L, ss_CI95R = calculateOR(n11, n1t-n11, n01, n0t-n01)\n",
    "output.write('OR\\t{}\\tp-value\\t{}\\nWald_95CI\\t{}\\nWald_90CI\\t{}\\nA&M_90CI\\t{}\\nA&M_95CI\\t{}\\n\\n'.format(OR_uMLE, pval, ','.join(map(lambda _: '{}'.format(_), [wald_MLE_CI90L, wald_MLE_CI90R])), ','.join(map(lambda _: '{}'.format(_), [wald_MLE_CI95L, wald_MLE_CI95R])), ','.join(map(lambda _: '{}'.format(_), [ss_CI90L, ss_CI90R])), ','.join(map(lambda _: '{}'.format(_), [ss_CI95L, ss_CI95R]))))\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining sites associated with age\n",
    "\n",
    "Finally, we perform association analyses to identify amino acid sites which substitution frequencies are associated with pair types (end-in-adult v. end-in-child). Here, we also identify if they are part of the receptor-binding or/and antigenic regions, as well as if they are potential glycosylation sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abspos_to_OR_results = {}\n",
    "for abs_pos in abspos_to_pt_to_count.keys():\n",
    "    # end-in-adult v. end-in-child\n",
    "    try:\n",
    "        n11 = abspos_to_pt_to_count[abs_pos]['CA']\n",
    "        #CA_11 = abspos_to_pt_to_count[abs_pos]['CA']\n",
    "    except:\n",
    "        n11 = 0\n",
    "        #CA_11 = 0\n",
    "\n",
    "    try:\n",
    "        n11 += abspos_to_pt_to_count[abs_pos]['AA']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        n01 = abspos_to_pt_to_count[abs_pos]['CC']\n",
    "    except:\n",
    "        n01 = 0\n",
    "\n",
    "    try:\n",
    "        n01 += abspos_to_pt_to_count[abs_pos]['AC']\n",
    "        #AC_11 = abspos_to_pt_to_count[abs_pos]['AC']\n",
    "    except:\n",
    "        #AC_11 = 0\n",
    "        pass\n",
    "\n",
    "    n10 = pt_count['CA'] + pt_count['AA'] - n11\n",
    "    n00 = pt_count['CC'] + pt_count['AC'] - n01\n",
    "\n",
    "    abspos_to_OR_results[abs_pos] = {'all': calculateOR(n11, n10, n01, n00)}#, 'caac': calculateOR(CA_11, pt_count['CA']-CA_11, AC_11, pt_count['AC']-AC_11)}\n",
    "\n",
    "# get q values\n",
    "all_OR_pvals = [abspos_to_OR_results[abs_pos]['all'][5] for abs_pos in abspos_to_OR_results.keys()]\n",
    "all_OR_qvals = sm.stats.multipletests(all_OR_pvals, method='fdr_bh')[1].tolist()\n",
    "all_pval_to_qval = {all_OR_pvals[_]:qvalue for _, qvalue in enumerate(all_OR_qvals)}\n",
    "\n",
    "with open('./files/{}/ageflu_age-associated-sites.{}'.format(subtype_to_analyse, outfname), 'w') as output:\n",
    "    output.write('abs_pos\\tref(H3)\\tref(H1)\\tref(B73)\\tRBS\\tAS\\tGS\\tPS\\t'\n",
    "                 'OR_uMLE\\twald_MLE_CI90L\\twald_MLE_CI90R\\twald_MLE_CI95L\\twald_MLE_CI95R\\t'\n",
    "                 'p-value\\tss_CI90L\\tss_CI90R\\tss_CI95L\\tss_CI95R\\tq-value\\t'\n",
    "                 'Mutations({})\\tAC\\tCA\\tAA\\tCC\\tEnd-in-Adult\\tEnd-in-Child\\tTotal\\n'.format(ref_subtype_dictionary[query_subtype]))\n",
    "    for abs_pos in abspos_to_OR_results.keys():\n",
    "        # reference positions\n",
    "        try:\n",
    "            main_ref_pos = queryST_to_refST_to_AbNum_to_RefNum[query_subtype][ref_subtype_dictionary[query_subtype]][abs_pos]\n",
    "        except:\n",
    "            main_ref_pos = '-'\n",
    "        try:\n",
    "            H3_ref_pos = queryST_to_refST_to_AbNum_to_RefNum[query_subtype]['H3'][abs_pos]\n",
    "        except:\n",
    "            H3_ref_pos = '-'\n",
    "        try:\n",
    "            H1_ref_pos = queryST_to_refST_to_AbNum_to_RefNum[query_subtype]['H1'][abs_pos]\n",
    "        except:\n",
    "            H1_ref_pos = '-'\n",
    "        try:\n",
    "            B_ref_pos = queryST_to_refST_to_AbNum_to_RefNum[query_subtype]['B73'][abs_pos]\n",
    "        except:\n",
    "            B_ref_pos = '-'\n",
    "\n",
    "        if re.search('(H1N1PDM09|H3N2)', query_subtype):\n",
    "            RBS_binary = 1 if H3_ref_pos in RBS_list else ''\n",
    "        else:\n",
    "            RBS_binary = 1 if main_ref_pos in RBS_list else ''\n",
    "\n",
    "        try:\n",
    "            if re.search('(H1N1PDM09|H3N2)', query_subtype):\n",
    "                AS_type = [_ for _ in AS_dict if H3_ref_pos in AS_dict[_]][0]\n",
    "            else:\n",
    "                AS_type = [_ for _ in AS_dict if main_ref_pos in AS_dict[_]][0]\n",
    "        except:\n",
    "            AS_type = ''\n",
    "        GS_binary = 1 if abs_pos in all_potential_glycosylation_sites else ''\n",
    "        PS_binary = 1 if H3_ref_pos in SebastianPas else ''\n",
    "\n",
    "        # OR results\n",
    "        all_OR_result = map(str, ['{:4f}'.format(_) if isinstance(_, float) else _ for _ in abspos_to_OR_results[abs_pos]['all']])\n",
    "        #caac_OR_result = map(str, ['{:4f}'.format(_) if isinstance(_, float) else _ for _ in abspos_to_OR_results[abs_pos]['caac']])\n",
    "\n",
    "        # substitutions\n",
    "        substitution_line = ['{}({})'.format(re.sub(str(abs_pos), str(main_ref_pos), substitution), ','.join(['{}:{}'.format(pt, count) for pt, count in abspos_to_mutation_to_pt_to_count[abs_pos][substitution].items()])) for substitution in abspos_to_mutation_to_pt_to_count[abs_pos].keys()]\n",
    "\n",
    "        # pair counts\n",
    "        count_line = []\n",
    "        end_in_adult_count, end_in_child_count = 0, 0\n",
    "        try:\n",
    "            count_line.append(abspos_to_pt_to_count[abs_pos]['AC'])\n",
    "            end_in_adult_count += abspos_to_pt_to_count[abs_pos]['AC']\n",
    "        except:\n",
    "            count_line.append(0)\n",
    "\n",
    "        try:\n",
    "            count_line.append(abspos_to_pt_to_count[abs_pos]['CA'])\n",
    "            end_in_child_count += abspos_to_pt_to_count[abs_pos]['CA']\n",
    "        except:\n",
    "            count_line.append(0)\n",
    "\n",
    "        try:\n",
    "            count_line.append(abspos_to_pt_to_count[abs_pos]['AA'])\n",
    "            end_in_adult_count += abspos_to_pt_to_count[abs_pos]['AA']\n",
    "        except:\n",
    "            count_line.append(0)\n",
    "\n",
    "        try:\n",
    "            count_line.append(abspos_to_pt_to_count[abs_pos]['CC'])\n",
    "            end_in_child_count += abspos_to_pt_to_count[abs_pos]['CC']\n",
    "        except:\n",
    "            count_line.append(0)\n",
    "\n",
    "        count_line = count_line + [end_in_adult_count, end_in_child_count, end_in_adult_count+end_in_child_count]\n",
    "\n",
    "        write_line = map(str, [abs_pos, H3_ref_pos, H1_ref_pos, B_ref_pos, RBS_binary, AS_type, GS_binary, PS_binary, '\\t'.join(all_OR_result), all_pval_to_qval[abspos_to_OR_results[abs_pos]['all'][5]], ';'.join(substitution_line), '\\t'.join(map(str, count_line))])\n",
    "\n",
    "        output.write('{}\\n'.format('\\t'.join(write_line)))\n",
    "        output.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
